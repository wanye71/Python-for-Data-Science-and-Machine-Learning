# Python for Data Science and Machine Learning

## Table of Contents

1. [Filtering and selecting](#filtering-and-selecting)
2. [Treating missing values](#treating-missing-values)
3. [Removing duplicates](#removing-duplicates)
4. [Concatenating and transforming](#concatenating-and-transforming)
5. [Grouping and aggregation](#grouping-and-aggregation)

### Filtering and selecting
```python
# Aight, let's get this party started with some heavy hitters!

# First up, we're summoning the 'np' library into the mix. This bad boy is like the Swiss Army knife of numerical computing!
# It's like having a superhero by our side, ready to crunch numbers and tackle any math challenge.

import numpy as np  # Get ready to crunch numbers like a boss!

# Next on the lineup, we're bringing in the 'pd' library. This powerhouse is the backbone of our data adventures!
# It's like having a master chef in the kitchen, ready to whip up delicious datasets and serve them with style.

import pandas as pd  # Get ready to dive deep into the world of data with pandas!

# And last but not least, we're summoning the 'DataFrame' class from the 'pandas' library.
# It's like having the VIP pass to the data party, giving us access to all the exclusive features and functionalities.

from pandas import DataFrame  # Get ready to create some epic DataFrames!


# Now, let's use the 'DataFrame' class to create our DataFrame.
# We're passing the sequence of numbers generated by 'np.arange' to the DataFrame constructor.
# We're also specifying the shape of the DataFrame as 10 rows and 3 columns using the 'reshape' function.
# It's like sculpting our data masterpiece, molding it into the perfect shape.

numbers_df = DataFrame(
    np.arange(0, 90, 3).reshape(10, 3),  # Generating a sequence of numbers from 0 to 90 (exclusive) with a step size of 3, reshaping it into a 10x3 array
    index=['row 1', 'row 2', 'row 3', 'row 4', 'row 5', 'row 6', 'row 7', 'row 8', 'row 9', 'row 10'],  # Assigning index labels for each row
    columns=['column 1', 'column 2', 'column 3']  # Assigning column labels for each column
)

numbers_df  # Returning the DataFrame

# Get ready to feast your eyes on the data masterpiece we've just created!


# Now, let's break down this code snippet and understand what each part does:

# numbers_df: This is our DataFrame object containing the numerical data.

# .iloc: This is a method of the DataFrame object used for integer-location based indexing.
# It allows us to access specific rows and columns using integer indices.

# [0, 1]: Within the .iloc method, we're specifying the row and column indices we want to access.
# In this case, 0 refers to the first row (because indexing starts from 0) and 1 refers to the second column.

# So, numbers_df.iloc[0, 1] retrieves the value at the intersection of the first row and second column in the DataFrame numbers_df.

# In simpler terms, it's like pinpointing a specific cell in a table (DataFrame) by its row and column numbers,
# and fetching the value stored in that cell.

# Let's execute the code and see what value it retrieves.

numbers_df.iloc[0, 1]


# Alright, let's break it down step by step:

# We're assigning the value 20 to the cell located at the intersection of the first row and second column in the DataFrame 'numbers_df'.
# The .iloc method is used for integer-location based indexing, and [0, 1] specifies the row and column indices.
# So, we're modifying the value at row 1, column 2 (because indexing starts from 0).

numbers_df.iloc[0, 1] = 20

# Now, let's print the updated DataFrame 'numbers_df' to see the changes made.
# We're displaying the DataFrame after the value assignment to visualize the updated data.

numbers_df


# Yo, check it out! We're about to flex some data skills:

# We're using fancy indexing with the .iloc method to select specific rows and columns from 'numbers_df'.
# This line of code is like cherry-pickin' the freshest data points from the block.
# We're rollin' with rows 1, 3, and 5, and columns 0 and 2.

numbers_df.iloc[[1, 3, 5], [0, 2]]


# Alright, let's break it down street style:

# We're cookin' up a boolean mask by layin' down a condition on the DataFrame 'numbers_df'.
# In this case, we're checkin' if each value in 'numbers_df' is straight-up greater than 30.
# The result is a DataFrame of boolean values, where 'True' means that the corresponding value in 'numbers_df' is higher than 30,
# and 'False' means it ain't.

mask = numbers_df > 30

# Now, let's peep the boolean mask to see what's poppin'.
# The mask shows us which values in 'numbers_df' keep it real by meetin' the condition (higher than 30) and which ones ain't cuttin' it.

mask


# Alright, check it out fam, we're about to drop some mad skills:

# We're usin' the boolean mask we cooked up earlier to filter out the values in 'numbers_df' that match the condition.
# This line of code is like siftin' through the data hood and pickin' out only the values that meet the criteria.
# We're only keepin' it real with the values that passed the test, where the corresponding cell in 'mask' is 'True'.

numbers_df[mask]


# Yo, check it fam! We're about to flip the script on these numbers:

# We're using a conditional statement to create a boolean mask where values in 'numbers_df' greater than 30 are flagged.
# Then, we're setting all these high-rolling numbers to 0, like wiping the slate clean.
# It's like saying, "Nah, we ain't playin' that game no more!"

numbers_df[numbers_df > 30] = 0

# Now, let's peep the updated 'numbers_df' after droppin' those high flyers down to zero.
# It's a whole new vibe, like starting fresh on a brand new day!

numbers_df


# Yo, peep this! We're about to slice and dice some data:

# We're using the .iloc method to select a range of rows from index 2 to 5 (exclusive) and columns from index 1 to 2 (exclusive).
# It's like carvin' out a fresh slice of data pie, grabbin' only the juiciest bits from rows 3 to 6 and columns 2 to 3.

numbers_df.iloc[2:6, 1:3]
```

### Treating missing values
```python
# Yo, we're gearing up for some serious data hustlin':

# First up, we're summoning the almighty numpy library, ready to crunch numbers like a boss.
# It's like having a math wizard by our side, ready to drop some serious calculations.

# Get ready to crunch numbers like a boss!
import numpy as np  

# Next in line, we're bringing in the pandas library to the mix.
# This powerhouse is the backbone of our data adventures, letting us tame and wrangle our datasets with ease.
# It's like having a data guru on standby, guiding us through the data jungle.

# Get ready to dive deep into the world of data with pandas!
import pandas as pd  

# And last but not least, we're cherry-picking the DataFrame class from the pandas library.
# It's like snagging the VIP pass to the data party, granting us access to all the exclusive features and functionalities.
# We're ready to craft some epic DataFrames!

# Get ready to create some epic DataFrames!
from pandas import DataFrame  

### Filling missing values using fillna(), replace() and interpolate()
# Aight, let's cook up some fresh data, fam:

# We're crafting a dictionary called 'data' containing the dope details of our crew.
# Each key represents a feature: 'names', 'age', 'gender', and 'rank'.
# It's like putting together a crew roster for our data squad, complete with their stats.

data = {'names': ['Steve', 'John', 'Richard', 'Sarah', 'Randy', 'Michael', 'Julie'],
        'age': [20, 22, 20, 21, 24, 23, 22],
        'gender': ['Male', 'Male', 'Male', 'Female', 'Male', 'Male', 'Female'],
        'rank': [2, 1, 4, 5, 3, 7, 6]}

# Now, let's assemble this crew into a DataFrame called 'ranking_df'.
# It's like putting together our dream team lineup, ready to conquer the data world!

ranking_df = DataFrame(data)

# Let's peep the 'ranking_df' to see our crew in action.
# Get ready to meet the squad and see who's bringin' the heat!

ranking_df

# Yo, we're about to shake things up with some missing values:

# We're using .iloc to target rows 2 to 4 (inclusive) and column 1, and setting those values to NaN.
# It's like creating a little mystery in our data, leaving those spots empty for now.

ranking_df.iloc[2:5, 1] = np.nan

# Now, we're targeting rows 3 to 5 (inclusive) and column 3, and dropping some NaN bombs in there.
# It's like adding another layer of intrigue, making our data even more mysterious.

ranking_df.iloc[3:6, 3] = np.nan

# Oh snap! We're taking it up a notch and dropping an entire row of NaN values.
# It's like saying, "Peace out, row 4! You're on vacation now."

ranking_df.iloc[3, :] = np.nan

# Now, let's peep the updated 'ranking_df' to see the effects of our data shenanigans.
# Get ready for some missing values, adding a bit of spice to our crew lineup!

ranking_df

# Yo, check it! We're about to uncover some hidden gems:

# We're using the .isnull() method to detect missing values (NaN) in the 'ranking_df'.
# It's like shining a spotlight on our data, exposing those empty spots we left behind.

ranking_df.isnull()

# Yo, fam! We're flipping the script and checking out the real deal:

# We're unleashing the .notnull() method on the 'ranking_df' to spot all the places where we ain't got no missing values.
# It's like shining a spotlight on the data and highlighting all the spots that are filled with real, solid information.

ranking_df.notnull()

# Yo, check it! We're about to uncover some hidden gems:

# We're using the pd.isnull() function to create a boolean series called 'bool_series'.
# This series will have True where the 'age' column in 'ranking_df' has missing values (NaN), and False otherwise.
# It's like shining a flashlight on the 'age' column and flagging all the spots where we're missing data.

bool_series = pd.isnull(ranking_df['age'])

# Now, we're filtering 'ranking_df' using 'bool_series' to display only the rows where the 'age' column has missing values.
# It's like zooming in on the specific rows where we're missing some key info about our crew.

ranking_df[bool_series]

# Ayo, we're about to patch up those missing spots like a pro:

# We're using the .fillna() method to replace all missing values (NaN) in 'ranking_df' with 0.
# It's like fixing up our crew lineup, filling in the blanks with some placeholder values.

ranking_df.fillna(0)

# Ayo, we're about to patch up those missing spots like a pro:

# We're using the .fillna() method with the 'pad' method parameter to replace missing values (NaN) in 'ranking_df'.
# With 'pad', also known as 'ffill' (forward fill), we're filling in missing values with the last observed non-null value in the column.
# It's like sliding down the block and filling in the gaps with the last known info.

ranking_df.fillna(method='pad')

# We're bout to patch up those missing spots like a pro:

# We're using the .fillna() method with the 'bfill' method parameter to replace missing values (NaN) in 'ranking_df'.
# With 'bfill', also known as 'backfill' (backward fill), we're filling in missing values with the next observed non-null value in the column.
# It's like cruising through the block and filling in the gaps with the next piece of info.

ranking_df.fillna(method='bfill')

# Now it's time to level up and interpolate like a pro:

# We're using the .interpolate() method with the 'linear' method parameter to replace missing values (NaN) in 'ranking_df'.
# With 'linear' interpolation, we're filling in missing values by linearly interpolating between existing values in the column.
# It's like smoothly connecting the dots, filling in the blanks with a straight line.

ranking_df.interpolate(method='linear')

# Ayo, we're about to clean house and drop some rows like a boss:

# We're using the .dropna() method to drop rows from 'ranking_df' where any value is missing (NaN).
# It's like sweeping through the data and removing any rows that have missing or incomplete information.
# We're keeping it tight and only rolling with the complete data.

ranking_df.dropna()

# Ayo, we're about to clean house and drop some rows like a boss:

# We're using the .dropna() method with the 'how' parameter set to 'all'.
# This means we're only dropping rows from 'ranking_df' where all values are missing (NaN).
# It's like doing a thorough check and only removing rows that are completely empty.
# We're keeping it real and only getting rid of the rows that offer no valuable info.

ranking_df.dropna(how='all')

ranking_df.dropna(axis=1)
# Ayo, we're about to clean house and drop some rows like a boss:

# We're using the .dropna() method with the 'axis' parameter set to 0 (which is the default).
# This means we're dropping rows from 'ranking_df' where any value is missing (NaN).
# It's like doing a quick scan and getting rid of any rows that have missing or incomplete information.
# We're keeping it tight and only rolling with the complete data.

ranking_df.dropna(axis=0)
```

### Removing duplicates
```python

```

### Concatenating and transforming
```python

```

### Grouping and aggregation
```python

```